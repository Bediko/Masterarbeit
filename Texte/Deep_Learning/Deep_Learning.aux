\relax 
\providecommand{\transparent@use}[1]{}
\citation{Hopfield}
\@writefile{toc}{\contentsline {section}{\numberline {1}Grundlagen}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Hopfield Netze}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Modell eines Hopfield Netzes. Alle Neuronen besitzen eine Ein- und Ausgabe und sind \IeC {\"u}ber Gewichte jeweils mit allen anderen Neuronen verbunden\relax }}{3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{HopfieldNetz}{{1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Boltzmann Maschinen}{3}}
\citation{BM}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Modell einer Boltzmann Maschine. Gelbe Kreise stellen verstecke Neuronen dar, wei\IeC {\ss }e Kreise sind sichtbare Neuronen.\relax }}{4}}
\newlabel{Boltzmannmaschine}{{2}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Eingeschr\IeC {\"a}nkte Boltzmann Maschinen}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Modell einer eingeschr\IeC {\"a}nkten Boltzmann Maschine. Oben sind die versteckten Knoten und unten die nach au\IeC {\ss }en sichtbaren Knoten.\relax }}{5}}
\newlabel{RBM}{{3}{5}}
\citation{guide}
\citation{Guide}
\newlabel{ph}{{10}{6}}
\citation{KLD}
\citation{noconv}
\citation{digits}
\newlabel{pv}{{11}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Kontrastive Divergenz}{7}}
\citation{learning}
\@writefile{toc}{\contentsline {section}{\numberline {2}Deep-Belief Netze}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Greedy Algorithmus zum trainieren von Deep-Belief Netzen}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Hyprid Netzwerk. Die Ebenen $H_3$ und $H_2$ sind mit ungerichteten Kanten verbunden und bilden einen Assoziativspeicher. Die anderen Ebenen sind mit gerichteten Kanten verbunden.\relax }}{8}}
\newlabel{Netz}{{4}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Beispiel f\IeC {\"u}r den Explained Away Effekt. Der Bias von $-10$ am Erdbebenknoten bedeutet dass dieser ohne beobachtet zu werden $e^10$ mal wahrscheinlicher aus als aktiviert ist. Beide Ereignisse zusammen haben eine Wahrscheinlichkeit von $e^{-20}$. Dies ist also sehr unwahrscheinlich. Deshalb erkl\IeC {\"a}rt die Aktivierung eines Knotens den anderen weg.\relax }}{9}}
\newlabel{ExplainedAway}{{5}{9}}
\citation{learning}
\citation{backprop}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Deep-Belief Netze zur Klassifikation}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Implementation}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Klassenherarchie des verwendeten Frameworks, rot umrandete Klassen wurden in dieser Arbeit hinzugef\IeC {\"u}gt.\relax }}{12}}
\newlabel{Aufbau}{{6}{12}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Implementation der Kontrastiven Divergenz\relax }}{13}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Versuchsaufbau}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Achsensymetrie und Rotationssymetrie}{14}}
\bibstyle{unsrt}
\bibcite{BM}{1}
\bibcite{guide}{2}
\bibcite{digits}{3}
\bibcite{noconv}{4}
\bibcite{learning}{5}
\bibcite{backprop}{6}
\bibcite{Hopfield}{7}
\bibcite{KLD}{8}
