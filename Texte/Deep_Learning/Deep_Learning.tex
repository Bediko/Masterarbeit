\documentclass[12pt]{article}


% for less space at the sides
\usepackage{a4wide}
% to display headings in german
\usepackage{ngerman}
% to corecctly display umlauts
\usepackage[utf8]{inputenc}
% for designing my own header
\usepackage{fancyhdr}
% to use colors by name
\usepackage[usenames,dvipsnames]{color}
\usepackage{subcaption}
\usepackage{xfrac}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage{cancel}
\usepackage{graphicx}
\usepackage{float}
\usepackage{tabularx}
\usepackage{tikz}
\usepackage{svg}


\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}



\newcommand{\highlight}[1]{\textcolor{Blue}{\textbf{\textit{#1}}}}
\newcommand{\emphasize}[1]{\textcolor{Gray}{\textit{#1}}}
\newcommand{\runtime}[1]{\textcolor{Red}{\textbf{#1}}}
\newcommand{\headline}[1]{\vspace{15pt}\textbf{#1}\vspace{10pt}}
\newcommand{\code}[1]{\textcolor{Green}{\texttt{#1}}}


\setlength{\parindent}{0pt}

% definition of the header
\pagestyle{fancy}
\fancyhead{}
\fancyfoot{}
\fancyhead[LO, LE]{Deep Learning}
\fancyhead[RE, RO]{\today}
\fancyhead[C]{\slshape Seite \thepage}

\title{Deep Learning}
\begin{document}

	\maketitle

	\newpage

	\tableofcontents
	
	\newpage
	\section{Eingeschränkte Boltzmann Maschinen}
	
	Ein Deep Belief Netzwerk besteht aus mehreren hintereinander geschalteten eingeschränkten Boltzmann Maschinen. Eine eingeschränkte Boltzmann Maschine ist ein Netzwerk mit zwei Ebenen(Layern) in dem stochastische binäre Pixel mit stochastisch binären Eigenschaftsdetektoren (feature detectors) verbunden sind, welche die Eigenschaften(features) der unbekannten Wahrscheinlichkeitsverteilung erkennen sollen. Stochastisch binär bedeutet, dass ein Knoten (Node) den Wert 1 annimmt, wenn ein Zufallswurf zwischen 1 und 100 höher als eine bestimmte Wahrscheinlichkeit ist. Die beiden Layer sind symmetrisch mit Gewichten verbunden.
	
	
	\begin{figure}[H]
	\includesvg[width=\textwidth]{Boltzmann}
	\caption{Modell einer eingeschränkten Boltzmann Maschine. Oben sind die versteckten Knoten und unten die nach außen sichtbaren Knoten.}
	\end{figure}

Als Eingabewerte in so ein Netzwerk sind reelle Werte möglich, jedoch wird der einfachheit halber angenommen, dass Binärbilder und damit binäre Vektoren als Eingabe verwendet werden. Da die Werte der Eingabeknoten beobachtet werden können, werden diese auch als sichtbar (visible) bezeichnet. Die Werte der Detektorschichte können nicht beobachtet werden, deshalb werden diese Knoten auch versteckt (hidden) genannt.

Eine Konfiguration $(\vec{v},\vec{h})$ aus visible und hidden Knoten wird nach Hopfield(1982) eine Energie zugewiesen:

\begin{equation}
E(\vec{v},\vec{h})= - \sum_{i \in visible} a_iv_i- \sum_{j \in hidden} b_j h_j - \sum_{i,j} v_i h_j w_{ij}
\end{equation}

Hierbei sind $v_i$ und $h_j$ die binären Zustände des sichtbaren Knotens $i$ und des versteckten Knotens $j$. $a_i$ und $b_j$ sind die Bias der entsprechenden Layer und $w_{ij}$ ist das Gewicht zwischen den beiden Knoten. Mit Hilfe dieser Energiefunktion weist das Netz jedem möglichen Paar von sichtbaren und versteckten Knoten eine Wahrscheinlichkeit zu:

\begin{equation}
p(\vec{v},\vec{h})= \frac{1}{Z} e^{-E(\vec{v},\vec{h})}
\end{equation}

Die Zustandssumme(partition function) $Z$ ergibt sich aus der Summe über alle möglichen Werte aus sichtbaren und versteckten Knoten und stellt einen Normierungsfaktor dar, damit die Gesamtwahrscheinlichkeit 1 ergibt:

\begin{equation}
Z=\sum_{\vec{v},\vec{h}} e^{-E(\vec{v},\vec{h})}
\end{equation}

Die Wahrscheinlichkeit, dass sich das Netzwerk einem Eingabebild anpasst, ergibt sich aus der Summe über alle versteckten Vektoren. \cite{guide}

\begin{equation}
p(\vec{v})= \frac{1}{Z} \sum_{\vec{h}} e^{-E(\vec{v},\vec{h})}
\end{equation}

Die Wahrscheinlichkeit, dass sich das Netz einem Trainingsbild anpasst kann erhöht werden, indem man die Bias und Energie der anderen Bilder erhöht. Vor allem für Bilder mit einer niedrigen Energie ist dies wichtig, da diese einen hohen Beitrag zur Zustanddsumme beitragen. Die Ableitung der Gewichte der logarithmischen Wahrscheinlichkeiten von Trainingsdaten ergibt sich wie folgt:

\begin{equation}
\frac{\partial \log p(\vec{v})}{\partial w_{ij}} = \langle v_ih_j \rangle_{data} - \langle v_i h_j \rangle_{model}
\end{equation}

Hierbei stellt $\langle...\rangle$ den Erwartungswert der realen Verteilung, als $data$ bezeichnet und der vom Netz modellierten Verteilung $model$ dar. Der Erwartungswert ist das Mittel der Wahrscheinlichkeitsverteilung wenn man aus dieser unbegrenzt viele Knotenverteilungen ziehen würde. Dies führt zu einer einfachen Lernregel für den stochastisch stärksten Aufstieg in der logarithmischen Wahrscheinlichkeit der Trainingsdaten:

\begin{equation}
\Delta w_{ij} = \epsilon\left( \langle v_i h_j \rangle_{data} - \langle v_i h_j \rangle_{model} \right)
\end{equation}
Da die versteckten Knoten innerhalb einer RBM nicht miteinander verbunden sind, sind diese statistisch voneinander unabhängig. Dies führt dazu, dass man sehr einfach eine Stichprobe ohne Bias für $\langle v_i h_j \rangle_{data}$ erhalten kann. Wenn ein zufällig ausgewähltes Trainingsbild $\vec{v}$ gegeben ist, wird der binäre zustand $h_j$ jedes versteckten Knotens $j$ mit folgender Wahrscheinlichkeit auf 1 gesetzt:

\begin{equation}
p(h_j = 1 | \vec{v}) = \sigma (b_j + \sum_{i} v_i w_{ij})
\label{ph}
\end{equation}

$\sigma(x)$ ist die logistische sigmoide Funktion $1/(1+e^{-x})$. $v_ih_j$ ist dann eine Stichprobe der Verteilung ohne Bias.

Da auch die sichtbaren Knoten keine Verbindungen untereinander haben und damit voneinander unabhängig sind, ist es genau so einfach eine Stichprobe für den Zustand eines sichtbaren Knotens zu erhalten wenn ein versteckter Vektor $\vec{h}$ gegeben ist:

\begin{equation}
p(v_i =1 | \vec{h}) = \sigma (a_i + \sum_{j} h_j w_{ij})
\label{pv}
\end{equation}

Eine Stichprobe ohne Bias für $<v_i h_j>_{model}$ zu erhalten, ist aufwändiger und kann über abwechselndes "' Gibbs sampling"' über einen langen Zeitraum berechnet werden. Beim Gibbs sampling beginnt man mit einem zufälligen Zustand der sichtbaren Knoten und hört auf, wenn ein Gleichgewichtszustand erreicht wird. Eine Iteration des Gibbs sampling besteht daraus, dass man zuerst parallel die Zuständer aller versteckten Knoten mit Gleichung \ref{ph} berechnet und im Anschluss mit Gleichung \ref{pv} die sichtbaren Knoten neu berechnet.

\subsection{Kontrastive Divergenz}

Ein schnelleres Verfahren als das Gibbs sampling besteht daraus, die Zustände der sichtbaren Knoten mit einem Trainingsvektor zu belegen. Anschließend werden die versteckten Knoten mit Gleichung \ref{ph} berechnet. Nachdem die binären Zustände der versteckten Knoten gefunden sind, wird eine "'Rekonstruktion"' angefertigt indem man jeden sichtbaren Knoten mit einer Wahrscheinlichkeit aus Gleichung \ref{pv} auf 1 setzt. Die Änderung in einem einzelnen Gewicht wird dadurch zu:

\begin{equation}
\Delta w_{ij} = \epsilon \left( \langle v_i h_j\rangle_{data} - \langle v_i h_j \rangle_{recon}\right)
\end{equation}

Diese Lernregel wird Kontrastive Divergenz(Contrastive Divergence(CD)) genannt und liefert bessere Ergebnisse als die vorherige Regel. Diese Lernregel folgt nicht dem Gradienten der logarithmsichen Wahrscheinlichkeit, sondern der Differnz zweier Kullback-Liebler Divergenzen. Da hierbei ein wichtiger Term jedoch vernachlässigt wird, folgt es auch diesem Gradienten nicht genau und Untersuchungen ergaben, dass der Gradient gar keiner Funktion folgt und trotzdem gut funktioniert \cite{noconv}. 

Die Idee hinter Kontrastiven Divergenz besteht darin, dass beim normalen Gibbs Sampling die Varianz innerhalb der entstehenden Markov-Kette immer weiter zunimmt und letztendlich den Schätzer der Ableitung verfälscht. Gleichzeitig wird die Varianz in den Proben immer abhängiger von den Parametern. Um dem entgegen zu wirken, wird für die Lernregel nicht eine Probe aus dem Gleichgewichtszustand der Boltzmann Maschine verwendet, sondern eine Probe aus der rekonstruierten Wahrscheinlichkeitsverteilung nach einem Schritt des Gibbs Sampling. Dies sorgt dafür dass die Markov-Kette näher an der tatsächlichen Wahrscheinlichkeitsverteilung der Eingabe bleibt und die Varianz geringer wird. Da die rekonstruierte Eingabe näher am Gleichgewichtzustand der Boltzmann Maschine ist als die Eingabe im Gibss Schritt davor, ist garantiert, dass die kontrastive Divergenz niemals negativ wird und nur Null erreicht wenn das Modell perfekt ist. \cite{digits}

Ein weiterer Schritt, um das Lernen eines Modells auf RBMs zu verbessern, besteht darin, $n$ Schritte des Gibbs samplings zu machen, bevor man die Statistik für $\langle v_i h_j \rangle_{recon}$ ermittelt. Dies wird mit $CD_n$ notiert, wobei $n$ die Anzahl der Schritte des Gibbs samplings angibt.

\section{Algorithmus zum lernen von Deep Belief Netzen}
Ein effizienter Weg ein kompliziertes Modell zu lernen, besteht darin, eine Menge von einfacheren Modellen nacheinander zu lernen. Die Idee des hier vorgestellten greedy Algorithmus besteht darin, dass jedes Modell eine andere Repräsentation der Daten darstellt. Dazu berechnet jedes Modell eine nichtlineare Transformation auf seine Eingabe und die Ausgabe eines Modells wird als Eingabe des nächsten Modells verwendet. 

\begin{figure}[H]
	\center
	\includesvg[width=150pt]{Netzwerk}
	\caption{Hyprid Netzwerk. Die Ebenen $H_3$ und $H_2$ sind mit ungerichteten Kanten verbunden und bilden einen Assoziativspeicher. Die anderen Ebenen sind mit gerichteten Kanten verbunden.}
	\label{Netz}
\end{figure}

In Abbildung \ref{Netz} ist ein generatives Modell (generative model)  mit mehreren Ebenen abgebildet. Als generatives Modell bezeichnet man Modelle die mit Hilfe von versteckten Parametern zufällig generierte beobachtbare Daten generieren wie zum Beispiel bei einer Markov-Kette. Die oberen beiden Ebenenen kommunizieren über ungerichtete Kanten und simulieren damit unendlich viele weitere Ebenen mit verbundenen Gewichten. Es gibt keine Verbindungen zwischen den Knoten einer Ebene und der Einfachheit halber wird angenommen, dass alle Ebenen gleich viele Knoten haben. Man kann gute Parameter für $W_0$ finden, indem man annimmt, dass die gleichen Gewichte zwischen den höheren Layern verwendet werden und damit eine komplementäre Verteilung (complementary prior) abbilden, um den "'Explained Away"'-Effekt für $W_0$ auszulöschen \cite{learning}.

Der "'Explained Away"'-Effekt beschreibt hierbei dass zwei Knoten stark gegeneinander korrelieren, also je höher die Wahrscheinlichkeit in einem Knoten ist, desto geringer ist sie in einem anderen. Bildhafter beschrieben ist die Ursache für ein wackelndes Haus durch ein hineinrasendes Auto sehr gering wenn bereits ein Erdbeben das Haus wackeln lässt. Hierbei wäre das Wackelnde Haus ein Ausgangsknoten und Erdbeben und das rasende Auto ein Eingangsknoten. Wenn einer der beiden Eingangsknoten also aktiviert ist wird das andere Ereignis sehr unwahrscheinlich. Dieses Verhalten macht es schwierig Schlussfolgerungen des Netzes nachzuvollziehen.  

Die Annahme, dass die höheren Layer eine komplementäre Verteilung bilden ist die Einschränkung, dass alle Gewichtsmatrizzen gleich, d.h. miteinander verbunden sind. Dies führt dazu, dass das Lernen von $W_0$ lediglich das trainieren einer RBM darstellt und mithilfe der Contrastive Divergence eine gute Approximination gefunden wird. Sobald $W_0$ gelernt ist, kann man $W^T_0$ als Eingabe für den ersten versteckten Layer benutzen.

Falls die RBM ein perfektes Modell für die Eingabedaten gefunden hat, sind die Gewichte der höheren Ebenen für die generierten Daten bereits perfekt. Generell ist dies jedoch nicht der Fall und das Modell kann durch einen einfachen greedy Algorithmus verbessert werden:

\begin{enumerate}
\item Lerne $W_0$ unter der Annahme, dass alle Gewichtsmatrizzen verbunden sind.
\item Entbinde $W_0$ und friere diese ein. Benutze $W_0^T$ um die Verteilung der einzelnen Variablen im ersten versteckten Layer zu approximieren.
\item Lerne eine RBM mithilfe der "'Daten"' die durch $W_0^T$ generiert wurden für den nächsten Layer.
\end{enumerate}

Wenn dieser Algorithmus die Gewichte in den höheren Layern ändert, wird das Modell immer verbessert. Gleichzeitig bedeutet dies auch, dass jedes Modell durch hinzufügen von neuen Layern verbessert werden kann, wenn man jeden Layer sorgfältig genug trainiert. Wenn alle Layer die gleiche Anzahl von Knoten haben, bietet dies den Vorteil, dass die höheren Ebenen bereits mit den gelernten Gewichten initialisiert werden können bevor diese entbunden werden, der Algorithmus funktioniert aber auch mit unterschiedlich großen Layern \cite{learning}.

\subsection{Backpropagation}
Nach dem lernen des Netzes mit dem Greedy Algorithmus sind die Gewichte in den unteren Layern nicht optimal und das ganze Netz wird noch einmal feiner eingestellt mit Hilfe des Backpropagation-Algorithmus. Dieser gehört zu den überwachten Lernverfahren und versucht eine Fehlerfunktion zu minimieren. Dazu werden die einzelnen Grauwerte der Farbpixel auf das Intervall $[0,1]$ abgebildet. Da der verwendete Datensatz hauptsächlich schwarz-weiss bilder beinhaltet und sich daher zwei Extrema bilden, bietet es sich an die logistische Funktion zur Modellierung zu verwenden. Das Netz wird dazu '"entfaltet"', sodass alle Kanten nur noch in eine Richtung zeigen, sodass das Netz aus einem "'Encoder"' Teil und einem "'Decoder"' Teil besteht.\cite{backprop}

\begin{thebibliography}{9}
\bibliographystyle{unsrt}
\bibitem{guide}
Geoffrey Hinton,
\emph{A Practical Guide to Training Restricted Boltzmann Machines},
Department of Computer Science, 
University of Toronto,
2010

\bibitem{digits}
Geoffrey Hinton,
\emph{Training Products of Experts by Minimizing Contrastive Divergence},
Neural Computation 14 Seite 1771-1800,
2002

\bibitem{noconv}
Ilya Sutske, Tijmen Tieleman,
\emph{On the convergence properties of contrastive divergence},
Proceedings of the 13th International Conference on Artificial Intelligence and Statistics (AISTATS),
2010 
\bibitem{learning}
Geoffrey Hinton, Yee-Whye Teh,
\emph{A Fast Learning Algorithm for Deep Belief Nets},
Neural Computation 18 Seiten 1527-1554,
2006

\bibitem{backprop}
G. E. Hinton, R. R. Salakhutdinov,
\emph{Reducing the dimensionality of data with neural networks},
Science Vol. 313. no. 5786n Seite 504 - 507,
2006

\end{thebibliography}



\end{document}

















































