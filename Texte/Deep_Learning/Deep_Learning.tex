\documentclass[12pt]{article}


% for less space at the sides
\usepackage{a4wide}
% to display headings in german
\usepackage{ngerman}
% to corecctly display umlauts
\usepackage[utf8]{inputenc}
% for designing my own header
\usepackage{fancyhdr}
% to use colors by name
\usepackage[usenames,dvipsnames]{color}
\usepackage{subcaption}
\usepackage{xfrac}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage{cancel}
\usepackage{graphicx}
\usepackage{float}
\usepackage{tabularx}
\usepackage{tikz}
\usepackage{svg}


\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}



\newcommand{\highlight}[1]{\textcolor{Blue}{\textbf{\textit{#1}}}}
\newcommand{\emphasize}[1]{\textcolor{Gray}{\textit{#1}}}
\newcommand{\runtime}[1]{\textcolor{Red}{\textbf{#1}}}
\newcommand{\headline}[1]{\vspace{15pt}\textbf{#1}\vspace{10pt}}
\newcommand{\code}[1]{\textcolor{Green}{\texttt{#1}}}


\setlength{\parindent}{0pt}

% definition of the header
\pagestyle{fancy}
\fancyhead{}
\fancyfoot{}
\fancyhead[LO, LE]{Deep Learning}
\fancyhead[RE, RO]{\today}
\fancyhead[C]{\slshape Seite \thepage}

\title{Deep Learning}
\begin{document}

	\maketitle

	\newpage

	\tableofcontents
	
	\newpage
	\section{Eingeschränkte Boltzmann Maschinen}
	
	Die ersten beiden Layer eines Deep Belief Netzes bilden eine eingeschränkte Boltzmann Maschine. Dies bedeutet, dass einen sichtbaren(visible) und einen versteckten(hidden) Layer gibt, die mit ungerichteten Kanten symettrisch verbunden sind, jedoch keine Verbindungen innerhalb eines Layers vorhanden sind.
	
	
	\begin{figure}[H]
	\includesvg[width=\textwidth]{Boltzmann}
	\caption{Modell einer eingeschränkten Boltzmann Maschine. Oben sind die versteckten Knoten und unten die nach außen sichtbaren Knoten.}
	\end{figure}

Einfacher kann man sich den sichtbaren Layer als stochastische binäre Pixel vorstellen die man von außen sehen kann, die mit einem stochastisch binären Feature Detektor verbunden sind. Als Eingabedaten werden binäre Vektoren verwendet.

Eine Konfiguration $(\vec{v},\vec{h})$ aus visible und hidden Knoten hat nach Hopfield(1982) eine Energie:

\begin{equation}
E(\vec{v},\vec{h})= - \sum_{i \in visible} a_iv_i- \sum_{j \in hidden} b_j h_j - \sum_{i,j} v_i h_j w_{ij}
\end{equation}

Hierbei sind $v_i$ und $h_j$ die binären Zustände des sichtbaren Knotens $i$ und des versteckten Knotens $j$. $a_i$ und $b_j$ sind die Biase der entsprechenden Layer und $w_{ij}$ ist das Gewicht zwischen den beiden Knoten. Mit Hilfe dieser Energiefunktion weist das Netz jedem möglichen paar von sichtbaren und versteckten Knoten eine Wahrscheinlichkeit zu:

\begin{equation}
p(\vec{v},\vec{h})= \frac{1}{Z} e^{-E(\vec{v},\vec{h})}
\end{equation}

Die Zustandssumme(partition function) $Z$ ergibt sich aus der Summe über alle möglichen paare aus sichtbaren und versteckten Knoten und stellt einen Normierungsfaktor dar, damit die Gesamtwahrscheinlichkeit 1 ergibt:

\begin{equation}
Z=\sum_{\vec{v},\vec{h}} e^{-E(\vec{v},\vec{h})}
\end{equation}

Die Wahrscheinlichkeit, dass das Netzwerk einen sichtbaren vektor zuweist, ergibt sich aus der Summe über alle versteckten vektoren. \cite{guide}

\begin{equation}
p(\vec{v})= \frac{1}{Z} \sum_{\vec{h}} e^{-E(\vec{v},\vec{h})}
\end{equation}

Die Wahrscheinlichkeit, dass sich das Netz einem Trainingsbild anpasst kann erhöht werden, indem man die Biase und Energie der anderen Bilder ehöht. Vor allem für Bilder mit einer niedrigen Energie ist dies wichtig, da diese einen hohen Beitrag zur Zustanddsumme beitragen. Die Ableitung der Gewichte der logarithmischen Wahrscheinlichkeiten von Trainingsdaten ergibt sich wie folgt:

\begin{equation}
\frac{\partial \log p(\vec{v})}{\partial w_{ij}} = \langle v_ih_j \rangle_{data} - \langle v_i h_j \rangle_{model}
\end{equation}

Hierbei stellt $\langle...\rangle$ den Erwartungswert der Verteilung dar und die Berechnung wird später erklärt. Dies führt zu einer einfachen Lernregel für den stochastisch stärksten Aufstieg in der logarithmischen Wahrscheinlichkeit der Trainingsdaten:

\begin{equation}
\Delta w_{ij} = \epsilon\left( \langle v_i h_j \rangle_{data} - \langle v_i h_j \rangle_{model} \right)
\end{equation}
Da die versteckten Knoten innerhalb einer RBM nicht miteinander verbunden sind, sind diese statistisch voneinander unabhängig. Dies führt dazu, dass man sehr einfach eine Stichprobe ohne Bias für $\langle v_i h_j \rangle_{data}$ erhalten kann. Wenn ein zufällig ausgewähltes Trainingsbild $\vec{v}$ gegeben ist, wird der binäre zustand $h_j$ jedes versteckten Knotens $j$ mit folgender Wahrscheinlichkeit auf 1 gesetzt:

\begin{equation}
p(h_j = 1 | \vec{v}) = \sigma (b_j + \sum_{i} h_j w_{ij})
\label{ph}
\end{equation}

$\sigma(x)$ ist die logistische sigmoid Funktion $1/(1+e^{-x})$. $v_ih_j$ ist dann eine Stichprobe ohne Bias.

Da auch die sichtbaren Knoten keine Verbindungen untereinander haben und damit voneinander unabhängig sind, ist es genau so einfach eine Stichprobe für den Zustand eines sichtbaren Knotens zu erhalten wenn ein versteckter Vektor $\vec{h}$ gegeben ist:

\begin{equation}
p(v_i =1 | \vec{h}) = \sigma (a_i + \sum_{j} h_j w_{ij})
\label{pv}
\end{equation}

Um eine Stichprobe ohne Bias für $<v_i h_j>_{model}$ zu erhalten ist aufwändiger und kann über abwechselndes "' Gibbs sampling"' über einen langen zeitraum berechnet werden. Beim Gibbs sampling beginnt man mit einem zufälligen Zustand der sichtbaren Knoten und hört auf, wenn ein Gleichgewichtszustand erreicht wird. Eine Iteration des Gibbs sampling besteht daraus, dass man zuerst parallel die Zuständer aller versteckten Knoten mit Gleichung \ref{ph} berechnet und im Anschluss mit Gleichung \ref{pv} die sichtbaren Knoten neu berechnet.

\subsection{Contrastive Divergence}

Ein schnelleres Verfahren als das Gibbs sampling besteht daraus, die Zustände der sichtbaren Knoten mit einem Trainingsvektor zu belegen. Anschliessend werden die versteckten Knoten mit Gleichung \ref{ph} berechnet. Nachdem die binären Zustände der versteckten Knoten gefunden sind, wird eine "'Rekonstruktion"' angefertigt indem man jeden sichtbaren Knoten mit einer Wahrscheinlichkeit aus Gleichung \ref{pv} auf 1 setzt. Die Änderung in einem einzelnen Gewicht wird dadurch zu (details siehe \cite{digits}):

\begin{equation}
\Delta w_{ij} = \epsilon \left( \langle v_i h_j\rangle_{data} - \langle v_i h_j \rangle_{recon}\right)
\end{equation}

Diese Lernregel wird '"Contrastive Divergence"' (CD) genannt und liefert bessere Ergebnisse als die vorherige Regel. Diese Lernregel folgt nicht dem Gradienten der logarithmsichen Wahrscheinlichkeit, sondern der Differnz zweier Kullback-Liebler Divergenzen. Da hierbei ein wichtiger Term jedoch vernachlässigt wird, folgt es auch diesem Gradienten nicht genau und untersuchungen ergaben, dass der Gradient gar keiner Funktion folgt und trotzdem gut funktioniert. \cite{noconv} Ein weiterer Schritt um das Lernen eines Modells auf RBMs zu verbessern, besteht darin, $n$ Schritte des Gibbs samplings zu machen bevor man die Statistik für $\langle v_i h_j \rangle_{recon}$ ermittelt. Dies wird mit $CD_n$ notiert, wobei $n$ die Anzahl der Schritte des Gibbs samplings angibt.

\section{Algorithmus zum lernen von Deep Belief Netzen}
Ein effizienter Weg ein kompliziertes Modell zu lernen, besteht darin, eine Menge von einfacheren Modellen nacheinander zu lernen. Die Idee des hier vorgestellten greedy Algorithmus besteht darin, dass jedes Modell eine andere Repräsentation der Daten darstellt. Dazu berechnet jedes Modell eine nichtlineare Transformation auf seine Eingabe und die Ausgabe eines Modells wird als Eingabe des nächsten Modells verwendet. 

\begin{figure}[H]
	\center
	\includesvg[width=150pt]{Netzwerk}
	\caption{Hyprid Netzwerk. Ebenen $H_3$ und $H_2$ haben ungerichtete Verbindungen und beilden einen assoziativen Speicher. Die anderen Ebenen sind von oben nach unten gerichtete Verbindungen die dem Zustand des Speichers auf ein Bild abbilden können. Die gerichteten Verbindugnen von unten nach oben stellen eine faktoriesierte Darstellung der binären Aktivitäten der Ebene darunter dar. Am Anfang des Trainings werden die Verbindungen pro Ebene als gleich angesehen.}
	\label{Netz}
\end{figure}

In Abbildung \ref{Netz} ist ein "'generative model"'  mit mehreren Ebenen abgebildet. Die oberen beiden Ebenenen kommunizieren über ungerichtete Kanten und simulieren damit unendlich viele weitere Ebenen mit verbundenen Gewichten. Es gibt keine Verbindungen zwischen den Knoten einer Ebene und der Einfachheit halber wird angenommen, dass alle Ebenen gleich viele Knoten haben. Man kann gute Parameter für $W_0$ finden, indem man annimmt, dass die Gewichte zwischen den höheren Layern verwendet werden um den "'Explained Away"'-Effekt für $W_0$ auszulöschen \cite{learning}. Dies ist genau so als wären alle Gewichte miteinander verbunden. Dies führt dazu, dass das lernen von $W_0$ lediglich das trainieren einer RBM darstellt und mithilfe der Contrastive Divergence eine gute approximination gefunden wird. Sobald $W_0$ gelernt ist, kann man $W^T_0$ als Eingabe für den ersten versteckten Layer benutzen.

Falls die RBM ein perfektes Modell für die Eingabedaten gefunden hat, sind die Gewichte der höheren Ebenen für die generierten Daten bereits perfekt. Generell ist dies jedoch nicht der Fall und das Modell kann durch einen einfachen greedy Algorithmus verbessert werden:

\begin{enumerate}
\item Lerne $W_0$ unter der Annahme dass alle Gewichtsmatrizzen verbunden sind.
\item Entbinde $W_0$ und friere diese ein. Benutze $W_0^T$ um die Verteilung der einzelnen Variablen im ersten versteckten Layer zu approximieren.
\item Lerne eine RBM mithilfe der "'Daten"' die durch $W_0^T$ generiert wurden für den nächsten Layer.
\end{enumerate}

Wenn dieser Algorithmus die Gewichte in den höheren Layern ändert, wird das Modell immer verbessert. Gleichzeitig bedeutet dies auch, dass jedes Modell durch hinzufügen von neuen Layern verbessert werden kann, wenn man jeden Layer sorgfältig genug trainiert. Wenn alle Layer die gleiche Anzahl von Knoten haben, bietet dies den Vorteil, dass die höheren Ebenen bereits mit den gelernten Gewichten initialisiert werden können bevor diese entbunden werden, der Algorithmus funktioniert aber auch mit unterschiedlich großen Layern. \cite{learning}

\subsection{Backpropagation}
Nach dem lernen des Netzes mit dem Greedy Algorithmus sind die Gewichte in den unteren Layern nicht optimal und das ganze Netz wird noch einmal feiner eingestellt. 

Hierzu nochmal \cite{backprop} anschauen für die richtigen Parameter-

\begin{thebibliography}{9}
\bibliographystyle{unsrt}
\bibitem{guide}
Geoffrey Hinton,
\emph{A Practical Guide to Training Restricted Boltzmann Machines},
Department of Computer Science, 
University of Toronto,
2010

\bibitem{digits}
Geoffrey Hinton,
\emph{Training Products of Experts by Minimizing Contrastive Divergence},
Neural Computation 14 Seite 1771-1800,
2002

\bibitem{noconv}
Ilya Sutske, Tijmen Tieleman,
\emph{On the convergence properties of contrastive divergence},
Proceedings of the 13th International Conference on Artificial Intelligence and Statistics (AISTATS),
2010 
\bibitem{learning}
Geoffrey Hinton, Yee-Whye Teh,
\emph{A Fast Learning Algorithm for Deep Belief Nets},
Neural Computation 18 Seiten 1527-1554,
2006

\bibitem{backprop}
G. E. Hinton, R. R. Salakhutdinov,
\emph{Reducing the dimensionality of data with neural networks},
Science Vol. 313. no. 5786n Seite 504 - 507,
2006

\end{thebibliography}



\end{document}

















































